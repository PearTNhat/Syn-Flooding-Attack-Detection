{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sklearn\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "from tabulate import tabulate\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline\n",
    "\n",
    "evaluate={'Acc':\"Accuracy\", 'b_Acc':\"Balanced Accuracy\", 'F1':\"F1 Score\", 'kap':\"Kappa\", 'ROC':\"Roc\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleep time:  3600 seconds\n",
      "Woke up after:  3 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# sleep for 3 seconds\n",
    "print('Sleep time: ', str(3600), 'seconds')\n",
    "#time.sleep(3600)\n",
    "print('Woke up after: ', str(3), 'seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mục đích: Thực hiện lựa chọn đặc trưng bằng thuật toán di truyền (GA). Hàm này bao gồm các bước khởi tạo quần thể, tính toán điểm fitness, chọn lọc, lai ghép, đột biến, và tiến hóa qua các thế hệ.\n",
    "# sửa bool  chromosome = np.ones(n_feat,dtype=bool)\n",
    "# sửa thuật toán muốn làm \n",
    "# sửa đầu ra list np.save(outputcsv.replace(\"csv\",\"npy\"), np_data)\n",
    "def GA(train,test,cols,gen_number=25,outputcsv=\"GA_output.csv\"):\n",
    "    #defining various steps required for the genetic algorithm\n",
    "    # GA adapted from https://datascienceplus.com/genetic-algorithm-in-machine-learning-using-python/\n",
    "    def initilization_of_population(size,n_feat):\n",
    "        population = []\n",
    "        for i in range(size):\n",
    "            chromosome = np.ones(n_feat,dtype=bool)\n",
    "            chromosome[:int(0.3*n_feat)]=False\n",
    "            np.random.shuffle(chromosome)\n",
    "            population.append(chromosome)\n",
    "        return population\n",
    "\n",
    "    def fitness_score(population):\n",
    "        scores = []\n",
    "        for chromosome in population:\n",
    "            logmodel.fit(X_train.iloc[:,chromosome],y_train)\n",
    "            predictions = logmodel.predict(X_test.iloc[:,chromosome])\n",
    "            scores.append(sklearn.metrics.f1_score(y_test,predictions,average= \"macro\"))\n",
    "        scores, population = np.array(scores), np.array(population) \n",
    "        inds = np.argsort(scores)\n",
    "        return list(scores[inds][::-1]), list(population[inds,:][::-1])\n",
    "\n",
    "    def selection(pop_after_fit,n_parents):\n",
    "        population_nextgen = []\n",
    "        for i in range(n_parents):\n",
    "            population_nextgen.append(pop_after_fit[i])\n",
    "        return population_nextgen\n",
    "\n",
    "    def crossover(pop_after_sel):\n",
    "        population_nextgen=pop_after_sel\n",
    "        for i in range(len(pop_after_sel)):\n",
    "            child=pop_after_sel[i]\n",
    "            child[3:7]=pop_after_sel[(i+1)%len(pop_after_sel)][3:7]\n",
    "            population_nextgen.append(child)\n",
    "        return population_nextgen\n",
    "\n",
    "    def mutation(pop_after_cross,mutation_rate):\n",
    "        population_nextgen = []\n",
    "        for i in range(0,len(pop_after_cross)):\n",
    "            chromosome = pop_after_cross[i]\n",
    "            for j in range(len(chromosome)):\n",
    "                if random.random() < mutation_rate:\n",
    "                    chromosome[j]= not chromosome[j]\n",
    "            population_nextgen.append(chromosome)\n",
    "        #print(population_nextgen)\n",
    "        return population_nextgen\n",
    "\n",
    "    def generations(size,n_feat,n_parents,mutation_rate,n_gen,X_train,\n",
    "                                       X_test, y_train, y_test):\n",
    "\n",
    "        best_chromo= []\n",
    "        best_score= []\n",
    "        population_nextgen=initilization_of_population(size,n_feat)\n",
    "        for i in tqdm(range(n_gen)):\n",
    "            second=time.time()\n",
    "            scores, pop_after_fit = fitness_score(population_nextgen)\n",
    "            #print(scores[:2])\n",
    "            zaman=time.time()-second\n",
    "\n",
    "            ths.write(f\"{np.mean(scores)},{np.mean(scores)},{zaman}\\n\")\n",
    "            \n",
    "\n",
    "\n",
    "            pop_after_sel = selection(pop_after_fit,n_parents)\n",
    "            pop_after_cross = crossover(pop_after_sel)\n",
    "            population_nextgen = mutation(pop_after_cross,mutation_rate)\n",
    "            best_chromo.append(pop_after_fit[0])\n",
    "            best_score.append(scores[0])\n",
    "        return best_chromo,best_score\n",
    "    \n",
    "\n",
    "    df = pd.read_csv(train,usecols=cols)#,header=None )\n",
    "    df=df.fillna(0)\n",
    "    #df = df.sample(n = 10000)\n",
    "    X_train =df[df.columns[0:-1]]\n",
    "    #X_train=np.array(X_train)\n",
    "    df[df.columns[-1]] = df[df.columns[-1]].astype('category')\n",
    "    y_train=df[df.columns[-1]].cat.codes  \n",
    "    df = pd.read_csv(test,usecols=cols)#,header=None )\n",
    "    df=df.fillna(0)\n",
    "    #df = df.sample(n = 10000)\n",
    "    X_test =df[df.columns[0:-1]]\n",
    "    #X_test=np.array(X_test)\n",
    "    df[df.columns[-1]] = df[df.columns[-1]].astype('category')\n",
    "    y_test=df[df.columns[-1]].cat.codes  \n",
    "    \n",
    "    \n",
    "    ths = open(f\"./{outputcsv}\", \"w\")\n",
    "    ths.write(\"MEAN,STD,TIME\\n\")\n",
    "    logmodel=SVC()\n",
    "    #print ('%-30s %-30s %-30s' % (\"MEAN\",\"STD\",\"TIME\"))\n",
    "    # size = 200 #The population will have 200 chromosomes , có 200 cá thể\n",
    "    # n_feat = X_train.shape[1] #Number of genes in a chromosome // 1 gene = 1 feature\n",
    "    # n_parents = 120 #Number of parents to select\n",
    "    chromo,score=generations(size=200,n_feat=X_train.shape[1],n_parents=120,mutation_rate=0.005,\n",
    "                         n_gen=gen_number,X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test)\n",
    "    #logmodel.fit(X_train.iloc[:,chromo[-1]],y_train)\n",
    "    #predictions = logmodel.predict(X_test.iloc[:,chromo[-1]])\n",
    "    #print(\"F1 Score score after genetic algorithm is= \"+str(sklearn.metrics.f1_score(y_test,predictions,average= \"macro\")))\n",
    "    ths.close()\n",
    "    sonuç=[]\n",
    "    for k,j in enumerate(chromo):\n",
    "        temp=X_train.iloc[:,j]\n",
    "        temp=list(temp.columns)\n",
    "        temp.append(\"Label\")\n",
    "        sonuç.append(temp)\n",
    "    \n",
    "    np.save(outputcsv.replace(\"csv\",\"npy\"), sonuç)\n",
    "    gf = pd.read_csv(outputcsv)\n",
    "    gf=gf[\"MEAN\"].values\n",
    "    gf=np.argmax(gf) \n",
    "    return sonuç[gf],gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder(f_name): #this function creates a folder named \"attacks\" in the program directory.\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print (\"The folder could not be created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_way(path,file_format,con=\"\"):\n",
    "    files_add = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file_format in file:\n",
    "                if con in file:\n",
    "                    files_add.append(os.path.join(r, file))  \n",
    "            \n",
    "    return files_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_list={\n",
    "\"RF\":RandomForestClassifier(),\n",
    "#bootstrap=False,criterion=\"gini\",max_depth=32,max_features=9,min_samples_split=3,n_estimators=148\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_name(name):\n",
    "    df = pd.read_csv(name,usecols=[\"Label\"])\n",
    "    target_names=sorted(list(df[\"Label\"].unique()))\n",
    "    return target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder(\"results\")\n",
    "folder(\"results/beforeGA/\")\n",
    "folder(\"results/afterGA/\")\n",
    "folder(\"pdfs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(train_time,test_time,predict,y_test,class_based_results,repeat,cv,dname,ml,sw):\n",
    "    train_time=train_time[0]\n",
    "    test_time=test_time[0]\n",
    "    rc=sklearn.metrics.recall_score(y_test, predict,average= \"macro\")\n",
    "    pr=sklearn.metrics.precision_score(y_test, predict,average= \"macro\")\n",
    "    f_1=sklearn.metrics.f1_score(y_test, predict,average= \"macro\")     \n",
    "    accuracy=sklearn.metrics.accuracy_score(y_test, predict)\n",
    "    accuracy_b=sklearn.metrics.balanced_accuracy_score( y_test,predict)\n",
    "    kappa=sklearn.metrics.cohen_kappa_score(y_test, predict,labels=None, weights=None, sample_weight=None)\n",
    "    try:\n",
    "        roc=sklearn.metrics.roc_auc_score(y_test, predict)\n",
    "    except:roc=0\n",
    "    report = sklearn.metrics.classification_report(y_test, predict, target_names=target_names,output_dict=True)\n",
    "    cr = pd.DataFrame(report).transpose()\n",
    "    line=[dname,sw,repeat,cv,ml,accuracy,accuracy_b,pr,rc,f_1,kappa,roc,train_time,test_time]\n",
    "\n",
    "    if class_based_results.empty:\n",
    "        class_based_results =cr\n",
    "    else:\n",
    "        class_based_results = class_based_results.add(cr, fill_value=0)\n",
    "    return class_based_results,line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thực hiện huấn luyện và đánh giá mô hình học máy với các tập dữ liệu và đặc trưng cụ thể bằng cách sử dụng phương pháp cross-validation.\n",
    "def ML_CV(loop1,loop2,output_csv,cols,dname,sw):\n",
    "    fold=5\n",
    "    repetition=10\n",
    "    # print\n",
    "    for ii in ml_list:\n",
    "        class_based_results=pd.DataFrame()#\"\" #pd.DataFrame(0, index=np.arange((len(target_names)+3)), columns=[\"f1-score\",\"precision\",\"recall\",\"support\"])\n",
    "        cm=pd.DataFrame()\n",
    "        cv=0\n",
    "        lines=[[\"Dataset\",\"SW\",\"T\",\"CV\",\"ML\",\"Acc\",\"b_Acc\",\"Prec\",\"Rec\",\"F1\",\"kap\",\"ROC\",\"tra-T\",\"test-T\"]]\n",
    "        for i in range(repetition):\n",
    "\n",
    "            #rnd = random()\n",
    "            \n",
    "            #kfold = sklearn.model_selection.KFold(n_splits=fold, shuffle=True, random_state=int(rnd*100))  \n",
    "            cv=0\n",
    "            df = pd.read_csv(loop1,usecols=cols)#,header=None )\n",
    "            df=df.fillna(0)\n",
    "            X_train =df[df.columns[0:-1]]\n",
    "            X_train=np.array(X_train)\n",
    "            df[df.columns[-1]] = df[df.columns[-1]].astype('category')\n",
    "            y_train=df[df.columns[-1]].cat.codes  \n",
    "\n",
    "\n",
    "            df = pd.read_csv(loop2,usecols=cols)#,header=None )\n",
    "            df=df.fillna(0)\n",
    "            X_test =df[df.columns[0:-1]]\n",
    "            X_test=np.array(X_test)\n",
    "            df[df.columns[-1]] = df[df.columns[-1]].astype('category')\n",
    "            y_test=df[df.columns[-1]].cat.codes  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #dname=loop1  [6:-13]  \n",
    "            results_y=[]\n",
    "            cv+=1\n",
    "            results_y.append(y_test)\n",
    "\n",
    "\n",
    "            precision=[]\n",
    "            recall=[]\n",
    "            f1=[]\n",
    "            accuracy=[]\n",
    "            train_time=[]\n",
    "            test_time=[]\n",
    "            total_time=[]\n",
    "            kappa=[]\n",
    "            accuracy_b=[]\n",
    "\n",
    "                #machine learning algorithm is applied in this section\n",
    "            clf = ml_list[ii]#choose algorithm from ml_list dictionary\n",
    "            second=time.time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            train_time.append(float((time.time()-second)) )\n",
    "            second=time.time()\n",
    "            predict =clf.predict(X_test)\n",
    "            test_time.append(float((time.time()-second)) )\n",
    "\n",
    "            altime=0\n",
    "            class_based_results,line=score(train_time,test_time,predict,y_test,class_based_results,cv,i,dname,ii,sw)\n",
    "            lines.append(line)\n",
    "            df_cm = pd.DataFrame(sklearn.metrics.confusion_matrix(y_test, predict))\n",
    "            if cm.empty:\n",
    "                cm =df_cm\n",
    "            else:\n",
    "                cm = cm.add(df_cm, fill_value=0)\n",
    "\n",
    "        results = pd.DataFrame (lines[1:], columns = lines[0])\n",
    "        results.to_csv(output_csv.replace(\"ML\",ii),index=False)\n",
    "        results=results.round(3)\n",
    "        print (tabulate(results, headers=list(results.columns)))\n",
    "        print()\n",
    "        \n",
    "        class_based_results=class_based_results/repetition\n",
    "        print (tabulate(class_based_results, headers=list(class_based_results.columns)))\n",
    "        class_based_results.to_csv(output_csv.replace(\".csv\",\"class_based_results.csv\"))\n",
    "        if True:\n",
    "            cm=cm//repetition\n",
    "            graph_name=output_csv[:-4]+\"_confusion matrix.pdf\"   \n",
    "            plt.figure(figsize = (5,3.5))\n",
    "            sns.heatmap(cm,xticklabels=target_names, yticklabels=target_names, annot=True, fmt='g')\n",
    "            plt.savefig(graph_name,bbox_inches='tight')#, dpi=400)\n",
    "            plt.show()\n",
    "            #print(cm)\n",
    "            print(\"\\n\\n\\n\")             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list={\n",
    "    \"SYN\":['./INPUT/SM/DoS-SYN-1.csv','./INPUT/SM/DoS-SYN-6.csv'],\n",
    "    # \"SYN_ARP\":['./train-data/train_syn_arp_data.csv','./train-data/test_syn_arp_data.csv'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mục đích: Định nghĩa danh sách các đặc trưng và tập tin dữ liệu để sử dụng trong quá trình huấn luyện và đánh giá mô hình.\n",
    "import json\n",
    "with open('GA_input.json', 'r') as fp:\n",
    "    feature_list = json.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#hực hiện huấn luyện và đánh giá mô hình học máy với các tập dữ liệu và đặc trưng cụ thể bằng cách sử dụng thuật toán di truyền để lựa chọn đặc trưng.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m file_list:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[0;32m      4\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeature_list[file]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file_list' is not defined"
     ]
    }
   ],
   "source": [
    "#hực hiện huấn luyện và đánh giá mô hình học máy với các tập dữ liệu và đặc trưng cụ thể bằng cách sử dụng thuật toán di truyền để lựa chọn đặc trưng.\n",
    "for file in file_list:\n",
    "    print(file)\n",
    "    features=feature_list[file]\n",
    "    train=file_list[file][0]\n",
    "    test=file_list[file][1]\n",
    "    #feature,_=GA(train,test,features,gen_number=25,outputcsv=f\"{file}_ET_chosed_GA_output.csv\")\n",
    "    # print(feature)\n",
    "    #GA_output[file]=feature\n",
    "    output_csv=f\"./results/beforeGA/{file}_chosed_output_ML_.csv\"\n",
    "    # target_names=['Benign','ARP-Spoofing','SYN-Flooding']\n",
    "    target_names=[0,1]\n",
    "    ML_CV(train,test,output_csv,features,file,5)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA_output={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for file in file_list:\n",
    "    print(file)\n",
    "    features=feature_list[file]\n",
    "    train=file_list[file][0]\n",
    "    test=file_list[file][1]\n",
    "    feature,_=GA(train,test,features,gen_number=25,outputcsv=f\"./results/afterGA/{file}_ET_chosed_GA_output.csv\")\n",
    "    \n",
    "    print(feature)\n",
    "    GA_output[file]=feature\n",
    "    output_csv=f\"./results/afterGA/{file}_chosed_output_ML_.csv\"\n",
    "    target_names=[1,0]\n",
    "    ML_CV(train,test,output_csv,feature,file,5)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GA_output_ET.json', 'w') as fp:\n",
    "    json.dump(GA_output, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "duration = 1000  # milliseconds\n",
    "freq = 440  # Hz\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!shutdown /s /t 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!shutdown -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
