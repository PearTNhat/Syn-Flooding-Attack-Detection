{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib  # Hoặc bạn có thể dùng pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols =[\n",
    "        \"ts\", #Time Stamp\n",
    "        \"IP_flags\", #IP fragmentation\n",
    "        \"IP_DF\", #IP Don’t Fragment\n",
    "        \"TCP_dataofs\", #TCP data ofset\n",
    "        \"TCP_SYN\", #Sync Flag\n",
    "        \"TCP_ACK\", #Acknowledgment Flag\n",
    "        \"sport_class\", #Source Port Class (IoTDevID classing)\n",
    "        \"dst_IP_diversity\",  #Number of Destination IP (by Source IP)\n",
    "        \"dst_port_diversity\",#Number of Destination Port (by Source IP)\n",
    "        \"pck_size_sum_of_EW\", #EW packet size total.\n",
    "        \"ts_diff\", #he time difference of consecutive packets\n",
    "        \"ts_std_WE\", #EW packet time Std.\n",
    "        \"ts_sum_of_EW\", #EW packet time total.\n",
    "        \"TCP_window_std_WE\", #EW TCP Windows size Std.\n",
    "        \"pck_size_mean_2\",  #RW (Rolling windows) packet size mean\n",
    "        \"ts_mean_2\", #RW packet time mean - Window size =2\n",
    "        \"ts_std_2\", #RW packet time Std.- Window size =2\n",
    "        \"TCP_window_mean_2\", #RW TCP Windows size mean - Window size =2\n",
    "        \"TCP_SYN_sum\", #Number of TCP Sync Flag\n",
    "        \"TCP_ACK_sum\", #EW Acknowledgment Flag\n",
    "        \"TCP_SYN_ratio\", #TCP_SYN/TCP_SYN_sum\n",
    "        \"TCP_ACK_SR\", #TCP_ACK/sum\n",
    "        \"ts_mean_6\",#RW packet time mean - Window size =6\n",
    "        \"ts_std_6\",#RW packet time Std.- Window size =6\n",
    "        \"pck_size_mean_9\",#\tRW (Rolling windows) packet size mean - Window size =9\n",
    "        \"ts_mean_9\",#RW packet time mean - Window size =9\n",
    "        \"ts_std_9\",#RW packet time Std.- Window size =9\n",
    "        \"TCP_window_mean_9\",#RW TCP Windows size mean - Window size =9\t\n",
    "        \"TCP_ACK_R\",#TCP_ACK_sum/sum\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>IP_flags</th>\n",
       "      <th>IP_DF</th>\n",
       "      <th>TCP_dataofs</th>\n",
       "      <th>TCP_SYN</th>\n",
       "      <th>TCP_ACK</th>\n",
       "      <th>sport_class</th>\n",
       "      <th>dst_IP_diversity</th>\n",
       "      <th>dst_port_diversity</th>\n",
       "      <th>pck_size_sum_of_EW</th>\n",
       "      <th>...</th>\n",
       "      <th>TCP_ACK_SR</th>\n",
       "      <th>TCP_ACK_R</th>\n",
       "      <th>pck_size_mean_9</th>\n",
       "      <th>ts_mean_9</th>\n",
       "      <th>ts_std_9</th>\n",
       "      <th>TCP_window_mean_9</th>\n",
       "      <th>pck_size_mean_2</th>\n",
       "      <th>ts_mean_2</th>\n",
       "      <th>ts_std_2</th>\n",
       "      <th>TCP_window_mean_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>459.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>2.063079</td>\n",
       "      <td>3.932673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>0.030851</td>\n",
       "      <td>0.043630</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>479.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>3.053064</td>\n",
       "      <td>4.462952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>0.030869</td>\n",
       "      <td>0.043656</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061702</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>918.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>2.063079</td>\n",
       "      <td>3.932673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>0.030851</td>\n",
       "      <td>0.043630</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061739</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>958.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>3.053064</td>\n",
       "      <td>4.462952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>0.030869</td>\n",
       "      <td>0.043656</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.101027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1377.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>2.063079</td>\n",
       "      <td>3.932673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>0.081365</td>\n",
       "      <td>0.027807</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ts  IP_flags  IP_DF  TCP_dataofs  TCP_SYN  TCP_ACK  sport_class  \\\n",
       "0  0.000000         1      0            0        0        0            9   \n",
       "1  0.000000         2      0            0        0        0            9   \n",
       "2  0.061702         1      0            0        0        0            9   \n",
       "3  0.061739         2      0            0        0        0            9   \n",
       "4  0.101027         1      0            0        0        0            9   \n",
       "\n",
       "   dst_IP_diversity  dst_port_diversity  pck_size_sum_of_EW  ...  TCP_ACK_SR  \\\n",
       "0                 1                   1               459.0  ...         0.0   \n",
       "1                 1                   1               479.0  ...         0.0   \n",
       "2                 1                   1               918.0  ...         0.0   \n",
       "3                 1                   1               958.0  ...         0.0   \n",
       "4                 1                   1              1377.0  ...         0.0   \n",
       "\n",
       "   TCP_ACK_R  pck_size_mean_9  ts_mean_9  ts_std_9  TCP_window_mean_9  \\\n",
       "0        0.0            459.0   2.063079  3.932673                0.0   \n",
       "1        0.0            479.0   3.053064  4.462952                0.0   \n",
       "2        0.0            459.0   2.063079  3.932673                0.0   \n",
       "3        0.0            479.0   3.053064  4.462952                0.0   \n",
       "4        0.0            459.0   2.063079  3.932673                0.0   \n",
       "\n",
       "   pck_size_mean_2  ts_mean_2  ts_std_2  TCP_window_mean_2  \n",
       "0            459.0   0.030851  0.043630                0.0  \n",
       "1            479.0   0.030869  0.043656                0.0  \n",
       "2            459.0   0.030851  0.043630                0.0  \n",
       "3            479.0   0.030869  0.043656                0.0  \n",
       "4            459.0   0.081365  0.027807                0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./INPUT/SM/DoS-SYN-6.csv\",usecols=cols)\n",
    "df.to_csv(\"./INPUT/SM/DoS-SYN-6-cols.csv\",index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xuất model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('INPUT/SM/DoS-SYN-1.csv',usecols=cols)#,header=None )\n",
    "# df=df[cols]\n",
    "# X_train =df[df.columns[0:-1]]\n",
    "# y_train=df[df.columns[-1]]\n",
    "\n",
    "# df = pd.read_csv('INPUT/VAL/VAL-SYN.csv',usecols=cols)#,header=None )\n",
    "# df=df.fillna(0)\n",
    "# df=df[cols]\n",
    "# X_test =df[df.columns[0:-1]]\n",
    "# y_test=df[df.columns[-1]]\n",
    "\n",
    "# # X_test = [\n",
    "# #     [0, 0, 1, 50, 1, 0, 1, 1, 5, 10, 0.1, 0.05, 0.2, 0.1, 50, 0.2, 0.1, 100, 200, 0.9, 0.1, 0.5, 0.1, 10, 0.2, 0.1, 0.05, 0.2, 0.8],  # SYN Flood\n",
    "# #     [1, 0, 0, 10, 0, 0, 0, 1, 1, 2, 0.05, 0.02, 0.1, 0.01, 5, 0.01, 0.02, 20, 10, 0.2, 0.05, 0.3, 0.01, 5, 0.03, 0.02, 0.01, 0.1, 0.2],  # Normal traffic\n",
    "# # ]\n",
    "# # y_test=[1,0]\n",
    "\n",
    "# model = RandomForestClassifier(bootstrap=False,criterion=\"gini\",max_depth=7,max_features=8,min_samples_split=2,n_estimators=98)\n",
    "# model.fit(X_train, y_train)\n",
    "# # Dự đoán trên tập test\n",
    "# y_pred = model.predict(X_test)\n",
    "# print(y_pred)\n",
    "# # Đánh giá hiệu suất\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# # Xuất mô hình ra file bằng joblib\n",
    "# joblib.dump(model, \"./model/syn_flood_detection.pkl\")\n",
    "# print(\"Model has been saved to 'svc_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thử nghiệm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./test/captured_20241210_202526_1_SW_1.csv',usecols=cols)#,header=None )\n",
    "df.to_csv('./test/real_a.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "Syn Flood\n",
      "No of Bengin: 143\n",
      "No of Syn Flood: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NHAT\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator GaussianNB from version 1.5.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\NHAT\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but GaussianNB was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tải mô hình từ file\n",
    "# loaded_model = joblib.load(\"./model/syn_flood_detection.pkl\")\n",
    "# loaded_model = joblib.load(\"./model/RF_SYN_1_model.pkl\")\n",
    "loaded_model = joblib.load(\"./model/NB_SYN_1_model.pkl\")\n",
    "\n",
    "df = pd.read_csv('./test/file_2_model_nhận_diện_sai.csv',usecols=cols)#,header=None )\n",
    "df=df.fillna(0)\n",
    "df=df[cols]\n",
    "# X_test =df[df.columns[0:-1]]\n",
    "X_test=df\n",
    "y_test=df[df.columns[-1]]\n",
    "# Dự đoán trên dữ liệu mới (giả sử bạn có X_new)\n",
    "new_predictions = loaded_model.predict(X_test)\n",
    "for i in range(len(new_predictions)):\n",
    "    if new_predictions[i]==1:\n",
    "        print(\"Syn Flood\")\n",
    "print('No of Bengin:',np.count_nonzero(new_predictions == 0))\n",
    "print('No of Syn Flood:',np.count_nonzero(new_predictions == 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
