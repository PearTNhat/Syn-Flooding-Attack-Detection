{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viPycSLZPOvt",
    "outputId": "d8dcd3d6-7380-4d82-a135-d77d50508e70"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "CXlGb7AdPOvu"
   },
   "outputs": [],
   "source": [
    "def folder(f_name): #this function creates a folder named \"attacks\" in the program directory.\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print (\"The folder could not be created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XEAfKlcnPOvv",
    "outputId": "38980d59-5ba4-4de6-e156-fb86f7877a86",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object walk at 0x000002C5BA28F120>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pcaps\\\\dos-synflooding-5-dec.pcap']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_the_way(path,file_format,con=\"\"):\n",
    "    files_add = []\n",
    "    # r=root, d=directories, f = files\n",
    "    print(os.walk(path))\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file_format in file:\n",
    "                if con in file:\n",
    "                    files_add.append(os.path.join(r, file))\n",
    "\n",
    "    return files_add\n",
    "path=\"pcaps\"\n",
    "files_add=find_the_way(path,'.pcap')\n",
    "files_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1D9kXP4POvw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nb9Io_nxPOvx"
   },
   "outputs": [],
   "source": [
    "def flag_fixer(file):\n",
    "\n",
    "    IP_flags={'0': 1,\n",
    " '<Flag 0 ()>': 2,\n",
    " '<Flag 2 (DF)>': 3,\n",
    " '<Flag 1 (MF)>': 4,\n",
    " '<Flag 3 (MF+DF)>': 40,\n",
    " '<Flag 4 (evil)>': 41,\n",
    " '<Flag 5 (MF+evil)>': 42,\n",
    " '<Flag 6 (DF+evil)>': 43,\n",
    " '<Flag 7 (MF+DF+evil)>': 44}\n",
    "    df=pd.read_csv(file)\n",
    "    IP_flags\n",
    "    \n",
    "    df[\"IP_flags\"]=df[\"IP_flags\"].map(IP_flags.get)\n",
    "\n",
    "    df.to_csv(file,index=None)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhtFBx88w82H"
   },
   "source": [
    "# PCAP2CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Rqb4fmeWw82I"
   },
   "outputs": [],
   "source": [
    "from scapy.all import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "a-667DUePOvz"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "knhnAWARPOvz"
   },
   "outputs": [],
   "source": [
    "def folder(f_name): #this function creates a folder.\n",
    "    try:\n",
    "        if not os.path.exists(f_name):\n",
    "            os.makedirs(f_name)\n",
    "    except OSError:\n",
    "        print (\"The folder could not be created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ak_Dk3mww82Q"
   },
   "outputs": [],
   "source": [
    "def shannon(data):\n",
    "    LOG_BASE = 2\n",
    "   # We determine the frequency of each byte\n",
    "   # in the dataset and if this frequency is not null we use it for the\n",
    "   # entropy calculation\n",
    "    dataSize = len(data)\n",
    "    ent = 0.0\n",
    "    freq={}\n",
    "    for c in data:\n",
    "        if c in freq:\n",
    "            freq[c] += 1\n",
    "        else:\n",
    "            freq[c] = 1\n",
    "   # to determine if each possible value of a byte is in the list\n",
    "    for key in freq.keys():\n",
    "        f = float(freq[key])/dataSize\n",
    "        if f > 0: # to avoid an error for log(0)\n",
    "            ent = ent + f * math.log(f, LOG_BASE)\n",
    "    return -ent\n",
    "\n",
    "def pre_entropy(payload):\n",
    "\n",
    "    characters=[]\n",
    "    for i in payload:\n",
    "            characters.append(i)\n",
    "    return shannon(characters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jkfuo7JCw82Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "LA0otM18FyXn"
   },
   "outputs": [],
   "source": [
    "def port_class(port):\n",
    "    port_list=[0,53,67,68,80,123,443,1900,5353,49153]# private port list (0-Reserved,53-DNS, 67-BOOTP server, 68-BOOTP client...)\n",
    "    if port in port_list: #Is the port number in the list?\n",
    "        return port_list.index(port)+1 # return the port's index number in the list (actually with index+1)\n",
    "    elif 0 <= port <= 1023: # return 11 if the port number is in the range 0 :1023\n",
    "        return 11\n",
    "    elif  1024 <= port <= 49151 : # return 12 if the port number is in the range 1024:49151\n",
    "        return 12\n",
    "    elif 49152 <=port <= 65535 :# return 13 if the port number is in the range 49152:65535\n",
    "        return 13\n",
    "    else:# return 0 if no previous conditions are met\n",
    "        return 0\n",
    "\n",
    "\n",
    "def port_1023(port):\n",
    "    if 0 <= port <= 1023:\n",
    "        return port\n",
    "    elif  1024 <= port <= 49151 :\n",
    "        return 2\n",
    "    elif 49152 <=port <= 65535 :\n",
    "        return 3\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "zqssqFuLw82R"
   },
   "outputs": [],
   "source": [
    "header=\"ts,IP_src,IP_dst,pck_size,IP_flags,IP_Z,IP_MF,IP_DF,TCP_dataofs,TCP_FIN,TCP_SYN,TCP_RST,TCP_PSH,TCP_ACK,TCP_URG,TCP_ECE,TCP_CWR,TCP_window,sport_class,sport_bare,dport_bare,TCP_sport,TCP_dport,UDP_sport,UDP_dport\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "tZKgl-4Kw82R"
   },
   "outputs": [],
   "source": [
    "#flags\n",
    "#TCP\n",
    "FIN = 0x01\n",
    "SYN = 0x02\n",
    "RST = 0x04\n",
    "PSH = 0x08\n",
    "ACK = 0x10\n",
    "URG = 0x20\n",
    "ECE = 0x40\n",
    "CWR = 0x80\n",
    "#IP\n",
    "Z = 0x00\n",
    "MF= 0x01\n",
    "DF= 0x02\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0U7RLVq3POv1"
   },
   "source": [
    "# Individual paket pased faetures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Nnwhr8XpPOv1"
   },
   "outputs": [],
   "source": [
    "def pcap_parser(oldname):\n",
    "    piece_size=50000\n",
    "    new_name=oldname.replace(\".pcap\",\"_smaller.pcap\")\n",
    "    command='C:/\\\"Program Files\\\"/Wireshark/editcap.exe -c '+str(piece_size)+\" \\\"\"+oldname+\"\\\" \"+new_name\n",
    "    os.system(command)\n",
    "    parsed=find_the_way(\"./\",new_name[6:-5])\n",
    "    return parsed,new_name[6:-5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "5s46XRyWPOv1"
   },
   "outputs": [],
   "source": [
    "def merged_csv(name,keyword):\n",
    "    for merger in [\"_FE.csv\",\"_WS.csv\"]:\n",
    "        merged_name=f\"{name[:-4]}{merger}\"\n",
    "        csv_files=find_the_way(\"./\",keyword,merger)\n",
    "        df=pd.read_csv(csv_files[0])\n",
    "        col_names=list(df.columns)\n",
    "\n",
    "        empty = pd.DataFrame(columns=col_names)\n",
    "        empty.to_csv(merged_name, mode=\"w\", index=False)#,header=False)\n",
    "\n",
    "\n",
    "        for j in csv_files:\n",
    "\n",
    "            df=pd.read_csv(j)\n",
    "            #print(\"name and shape of dataframe :\",i,df.shape)\n",
    "            df.to_csv(merged_name, mode=\"a\", index=False,header=False)\n",
    "            os.remove(j)\n",
    "            try:\n",
    "                os.remove(j.replace(\"_FE.csv\",\".pcap\"))\n",
    "            except:pass\n",
    "\n",
    "            #print(\"\\n\\n\\nname and shape of dataframe :\",name,df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6BKuGebw82S",
    "outputId": "787c2234-f638-48ad-abc2-3aa58bc26400",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1-pcaps\\dos-synflooding-5-dec.pcap\n",
      "ts,IP_src,IP_dst,pck_size,IP_flags,IP_Z,IP_MF,IP_DF,TCP_dataofs,TCP_FIN,TCP_SYN,TCP_RST,TCP_PSH,TCP_ACK,TCP_URG,TCP_ECE,TCP_CWR,TCP_window,sport_class,sport_bare,dport_bare,TCP_sport,TCP_dport,UDP_sport,UDP_dport\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11366/11366 [00:00<00:00, 14874.27it/s]\n"
     ]
    }
   ],
   "source": [
    "outputfolder=\"FE\"\n",
    "folder(outputfolder)\n",
    "for sayac,i in enumerate (files_add):\n",
    "    print(f\"{sayac+1}/{len(files_add)}-{i}\")\n",
    "    file_list=[i]\n",
    "    for isim in file_list:\n",
    "\n",
    "        filename=isim.replace(\".pcap\",\"_FE.csv\")\n",
    "        ths = open(filename, \"w\")\n",
    "        ths.write(header)\n",
    "        print(header)\n",
    "        pkt = rdpcap(isim)\n",
    "        for j in tqdm(pkt):\n",
    "            ts=float(j.time) #\n",
    "            try:pck_size=j.len #\n",
    "            except:pck_size=0\n",
    "           \n",
    "            if j.haslayer(IP): #\n",
    "                IP_Z = 0\n",
    "                IP_MF= 0\n",
    "                IP_DF= 0 #\n",
    "             \n",
    "                IP_flags=j[IP].flags#\n",
    "\n",
    "               \n",
    "\n",
    "                if IP_flags & Z:IP_Z = 1\n",
    "                if IP_flags & MF:IP_MF = 1\n",
    "                if IP_flags & DF:IP_DF = 1 #\n",
    "                \n",
    "                IP_src=j[IP].src#IP_adresses.index(j[IP].src)+1\n",
    "                IP_dst=j[IP].dst#IP_adresses.index(j[IP].dst)+1\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "                IP_Z = 0\n",
    "                IP_MF= 0\n",
    "                IP_DF= 0\n",
    "\n",
    "                # IP_version=0\n",
    "                # IP_ihl=0\n",
    "                # IP_tos=0\n",
    "                # IP_len=0\n",
    "                # IP_id=0\n",
    "                IP_flags=0\n",
    "                # IP_frag=0\n",
    "                # IP_ttl=0\n",
    "                # IP_proto=0\n",
    "                # IP_chksum=0\n",
    "                IP_src=0\n",
    "                IP_dst=0\n",
    "                # IP_options=0\n",
    "                # IP_add_count=0\n",
    "\n",
    "\n",
    "            if j.haslayer(TCP):\n",
    "                TCP_FIN = 0\n",
    "                TCP_SYN = 0 #\n",
    "                TCP_RST = 0\n",
    "                TCP_PSH = 0\n",
    "                TCP_ACK = 0 #\n",
    "                TCP_URG = 0\n",
    "                TCP_ECE = 0\n",
    "                TCP_CWR = 0\n",
    "                TCP_sport=j[TCP].sport\n",
    "                TCP_dport=j[TCP].dport\n",
    "                # TCP_seq=j[TCP].seq\n",
    "                # TCP_ack=j[TCP].ack\n",
    "                TCP_dataofs=j[TCP].dataofs #\n",
    "                # TCP_reserved=j[TCP].reserved\n",
    "                TCP_flags=j[TCP].flags\n",
    "\n",
    "                TCP_window=j[TCP].window #\n",
    "                # TCP_chksum=j[TCP].chksum\n",
    "                # TCP_urgptr=j[TCP].urgptr\n",
    "                # TCP_options=j[TCP].options\n",
    "                # TCP_options= str(TCP_options).replace(\",\",\"-\")\n",
    "                # if TCP_options!=\"0\":\n",
    "                #     TCP_options=1\n",
    "                # else:\n",
    "                #     TCP_options=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #if TCP_flags not in tcpf:\n",
    "                    #tcpf.append(TCP_flags)\n",
    "                #print(TCP_options)\n",
    "                if TCP_flags & FIN:TCP_FIN = 1\n",
    "                if TCP_flags & SYN:TCP_SYN = 1\n",
    "                if TCP_flags & RST:TCP_RST = 1\n",
    "                if TCP_flags & PSH:TCP_PSH = 1\n",
    "                if TCP_flags & ACK:TCP_ACK = 1\n",
    "                if TCP_flags & URG:TCP_URG = 1\n",
    "                if TCP_flags & ECE:TCP_ECE = 1\n",
    "                if TCP_flags & CWR:TCP_CWR = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "                TCP_sport=0\n",
    "                TCP_dport=0\n",
    "                # TCP_seq=0\n",
    "                # TCP_ack=0\n",
    "                TCP_dataofs=0\n",
    "                # TCP_reserved=0\n",
    "                TCP_flags=0\n",
    "                TCP_window=0\n",
    "                # TCP_chksum=0\n",
    "                # TCP_urgptr=0\n",
    "                # TCP_options=0\n",
    "                # TCP_options=0\n",
    "                TCP_FIN = 0\n",
    "                TCP_SYN = 0\n",
    "                TCP_RST = 0\n",
    "                TCP_PSH = 0\n",
    "                TCP_ACK = 0\n",
    "                TCP_URG = 0\n",
    "                TCP_ECE = 0\n",
    "                TCP_CWR = 0\n",
    "\n",
    "            if j.haslayer(UDP):\n",
    "                UDP_sport=j[UDP].sport\n",
    "                UDP_dport=j[UDP].dport\n",
    "                UDP_len=j[UDP].len\n",
    "                UDP_chksum=j[UDP].chksum\n",
    "            else:\n",
    "                UDP_sport=0\n",
    "                UDP_dport=0\n",
    "                UDP_len=0\n",
    "                UDP_chksum=0\n",
    "           \n",
    "            sport_class=port_class(TCP_sport+UDP_sport) #\n",
    "            \n",
    "            sport_bare=TCP_sport+UDP_sport\n",
    "            dport_bare=TCP_dport+UDP_dport#port_class(TCP_dport+UDP_dport)\n",
    "\n",
    "\n",
    "            try:Mac=j.src ############# thiếu trong xử lý py nếu lỗi thì thêm vào\n",
    "            except:Mac= j.addr1\n",
    "            line=[ts,  IP_src,\n",
    "            IP_dst, pck_size,\n",
    "            IP_flags,IP_Z, IP_MF,IP_DF  ,#\n",
    "            TCP_dataofs,TCP_FIN,\n",
    "            TCP_SYN, TCP_RST, TCP_PSH, TCP_ACK,  TCP_URG, TCP_ECE, TCP_CWR   , TCP_window,\n",
    "            sport_class,sport_bare, dport_bare,TCP_sport,TCP_dport,\n",
    "            UDP_sport,\n",
    "            UDP_dport\n",
    "            ]\n",
    "            #print(line)\n",
    "            line=str(line).replace(\"[\",\"\")\n",
    "            line=str(line).replace(\"]\",\"\")\n",
    "            #line=str(line).replace(\"\\',\",\"-\")\n",
    "            line=str(line).replace(\", \",\",\")\n",
    "            line=str(line).replace(\"\\'\",\"\")\n",
    "            line=str(line).replace(\"None\",\"0\")\n",
    "            # if label:\n",
    "            #     Label=df[label_count]\n",
    "            # else:\n",
    "            #     Label=\"No_Label\"\n",
    "            ths.write(str(line)+f\"\\n\")\n",
    "            # label_count+=1\n",
    "            \n",
    "        name=isim.replace(\"\\\\\",\"/\")\n",
    "        output=filename.replace(\"_FE.csv\",\"_WS.csv\")\n",
    "\n",
    "        if \" \" not in name:\n",
    "            command=f\"tshark -r {name}  -T fields -e _ws.col.Source -e _ws.col.Destination  \n",
    "            -e _ws.col.Protocol    -E header=y -E separator=, -E quote=d -E occurrence=f >{output}\"\n",
    "        else:\n",
    "            command=f\"tshark -r \\\"{name}\\\" -T fields -e _ws.col.Source -e _ws.col.Destination  \n",
    "            -e _ws.col.Protocol    -E header=y -E separator=, -E quote=d -E occurrence=f >\\\"{output}\\\"\"\n",
    "        os.system(command)\n",
    "        ths.close()\n",
    "    if len(file_list)>1:\n",
    "        merged_csv(i,keyword)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgQFcy_BPOv1"
   },
   "source": [
    "# WIRESHARK FEATURES dst,src and Protocol added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object walk at 0x000002C5B7E9E5A0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./pcaps\\\\dos-synflooding-5-dec_FE.csv']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_list=find_the_way('./pcaps','_FE.csv')\n",
    "name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8xFhNVuPOv1",
    "outputId": "89c346ae-9bc4-438c-8824-d61992a89d1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object walk at 0x000002C5B7E9E5A0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./pcaps\\dos-synflooding-5-dec_FE.csv\n",
      "./pcaps\\dos-synflooding-5-dec_FE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.84it/s]\n"
     ]
    }
   ],
   "source": [
    "name_list=find_the_way('./pcaps','_FE.csv')\n",
    "for i in tqdm(name_list):\n",
    "    print(i)\n",
    "    df=pd.read_csv(i)\n",
    "    WS_s_d=i.replace(\"_FE.csv\",\"_WS.csv\")\n",
    "    s_d=pd.read_csv(WS_s_d)\n",
    "    df[\"WS_src\"]=s_d[\"_ws.col.Source\"]\n",
    "    df[\"WS_dst\"]=s_d[\"_ws.col.Destination\"]\n",
    "    df[\"Protocol\"]=s_d[\"_ws.col.Protocol\"]\n",
    "    # y=df[\"Label\"]\n",
    "    # del df[\"Label\"]\n",
    "    # df[\"Label\"]=y\n",
    "    df.to_csv(i,index=None)\n",
    "    flag_fixer(i)\n",
    "    os.remove(WS_s_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "n6PTza1fPOv1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object walk at 0x000002C5B7E9E5A0>\n"
     ]
    }
   ],
   "source": [
    "name_list=find_the_way('./pcaps','_FE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwagDIAtPOv1"
   },
   "source": [
    "# NEW FEATURES: dst_IP_diversity, dst_port_diversity, src_IP_diversity IP_add_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3szS7Fr-POv2",
    "outputId": "430e1f48-944e-46dc-a7c6-9e9b959bc301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1-./pcaps\\dos-synflooding-5-dec_FE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11366/11366 [00:00<00:00, 16682.20it/s]\n"
     ]
    }
   ],
   "source": [
    "for sayac,i in enumerate (name_list):\n",
    "    print(f\"{sayac+1}/{len(name_list)}-{i}\")\n",
    "    dst_IP_diversity=[]\n",
    "    dst_port_diversity=[]\n",
    "    src_IP_diversity=[]\n",
    "    src_IP_v_dst_IP={}\n",
    "    src_IP_v_dst_port={}\n",
    "    df=pd.read_csv(i)\n",
    "    count=0\n",
    "    for j in tqdm(range(len(df))):\n",
    "        if df['IP_src'][j] in src_IP_v_dst_IP:\n",
    "            if df['IP_dst'][j] not in src_IP_v_dst_IP[df['IP_src'][j]]:\n",
    "                src_IP_v_dst_IP[df['IP_src'][j]].append(df['IP_dst'][j])\n",
    "        else:\n",
    "            src_IP_v_dst_IP[df['IP_src'][j]]=[]\n",
    "            src_IP_v_dst_IP[df['IP_src'][j]].append(df['IP_dst'][j])\n",
    "        dst_IP_diversity.append(len(src_IP_v_dst_IP[df['IP_src'][j]]))\n",
    "        ###############################################################################\n",
    "        #  gắn port tương tự như IP\n",
    "        if df['IP_src'][j] in src_IP_v_dst_port:\n",
    "            if df['dport_bare'][j] not in src_IP_v_dst_port[df['IP_src'][j]]:\n",
    "                src_IP_v_dst_port[df['IP_src'][j]].append(df['dport_bare'][j])\n",
    "        else:\n",
    "            src_IP_v_dst_port[df['IP_src'][j]]=[]\n",
    "            src_IP_v_dst_port[df['IP_src'][j]].append(df['dport_bare'][j])\n",
    "        dst_port_diversity.append(len(src_IP_v_dst_port[df['IP_src'][j]]))\n",
    "   \n",
    "    df[\"dst_IP_diversity\"]=dst_IP_diversity\n",
    "    df[\"dst_port_diversity\"]=dst_port_diversity\n",
    "    y=df[\"Label\"]\n",
    "    del df[\"Label\"]\n",
    "    df[\"Label\"]=y\n",
    "    df.to_csv(i,index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6QBp4vUPOv2"
   },
   "source": [
    "# Sliding Windows Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "lZsmTrUyPOv2"
   },
   "outputs": [],
   "source": [
    "outputfolder=\"FE\"\n",
    "folder(outputfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "owSD0VSRPOv2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object walk at 0x000002C5B7E9F120>\n"
     ]
    }
   ],
   "source": [
    "files_add=find_the_way('./pcaps','FE.csv')\n",
    "for i in files_add:\n",
    "    os.rename(i,i.replace(\"./pcaps\",'./FE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "DKbl23AAPOv2"
   },
   "outputs": [],
   "source": [
    "# Tính hiệu số giữa các giá trị liên tiếp trong danh sách x.\n",
    "def diff(x):\n",
    "    x = pd.Series(x)\n",
    "    result=x.diff()\n",
    "    result=result.fillna(0)\n",
    "    return result\n",
    "# Tính giá trị trung bình di động (rolling mean) với kích thước cửa sổ WS\n",
    "# Trả về danh sách trung bình di động.\n",
    "def mean(x,WS):\n",
    "    x = pd.Series(x)\n",
    "    result=x.rolling(WS).mean()\n",
    "    result=result.fillna(result[WS-1])\n",
    "    return result\n",
    "# Tính độ lệch chuẩn di động (rolling standard deviation) với kích thước cửa sổ WS\n",
    "# Tương tự hàm mean(x, WS), nhưng tính độ lệch chuẩn thay vì trung bình.\n",
    "def std(x,WS):\n",
    "    x = pd.Series(x)\n",
    "    result=x.rolling(WS).std()\n",
    "    result=result.fillna(result[WS-1])\n",
    "    return result\n",
    "# Tính trung bình mở rộng (expanding mean) cho tất cả giá trị từ đầu đến vị trí hiện tại.\n",
    "# Trả về danh sách trung bình mở rộng.\n",
    "def mean_EW(x):\n",
    "    x = pd.Series(x)\n",
    "    result=x.expanding(min_periods=1).mean()\n",
    "    return result\n",
    "# Tính độ lệch chuẩn mở rộng (expanding standard deviation).\n",
    "def std_EW(x):\n",
    "    x = pd.Series(x)\n",
    "    result=x.expanding(min_periods=1).std() # Tính độ lệch chuẩn cho tất cả giá trị từ đầu đến vị trí hiện tại.\n",
    "    result=result.fillna(0)\n",
    "    return result\n",
    "# Tính tổng mở rộng (expanding sum).\n",
    "# Tương tự mean_EW(x), nhưng tính tổng thay vì trung bình.\n",
    "def sum_of_EW(x):\n",
    "    x = pd.Series(x)\n",
    "    result=x.expanding(min_periods=1).sum()\n",
    "    return result\n",
    "# Tính phương sai di động (rolling variance) với kích thước cửa sổ WS.\n",
    "def var(x,WS):\n",
    "    x = pd.Series(x)\n",
    "    result=x.rolling(WS).var()\n",
    "    result=result.fillna(result[WS-1])\n",
    "    return result\n",
    "# Tính tổng tích lũy cho các giá trị 1 trong danh sách x.\n",
    "# Trả về danh sách với tổng tích lũy của các giá trị 1.\n",
    "def flagsum(x):\n",
    "    total_f=0\n",
    "    result=[]\n",
    "    for i in x:\n",
    "        if i==1:\n",
    "            total_f+=1\n",
    "        result.append(total_f)\n",
    "    return result\n",
    "# Tính số lượng cổng (port) duy nhất đã xuất hiện trong danh sách x tính đến từng thời điểm.\n",
    "# Trả về danh sách số lượng cổng duy nhất.\n",
    "def portsum(x):\n",
    "    total_ports=[]\n",
    "    result=[]\n",
    "    for i in x:\n",
    "        if i not in total_ports:\n",
    "            total_ports.append(i)\n",
    "        result.append(len(total_ports))\n",
    "    return result     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object walk at 0x000002C5B7E9F120>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./FE\\\\dos-synflooding-5-dec_FE.csv']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_add=find_the_way('./FE','FE.csv')\n",
    "files_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E89C1ZkfPOv2",
    "outputId": "d0a62126-817a-49bd-c6fe-266a813890d6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dos-synflooding-5-dec_FE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10562/10562 [01:31<00:00, 115.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -------------------------------------------------------------------------------\n",
      "dos-synflooding-5-dec_FE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10562/10562 [01:28<00:00, 118.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 -------------------------------------------------------------------------------\n",
      "dos-synflooding-5-dec_FE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10562/10562 [01:29<00:00, 117.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 -------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "outputfolder=\"SW\"\n",
    "folder(outputfolder)\n",
    "for windows_size in [2,6,9]:\n",
    "    for j in files_add:\n",
    "        print(j[5:])\n",
    "        df=pd.read_csv(j)#,usecols=n)\n",
    "        df.drop(columns=[\"UDP_sport\", \"TCP_sport\", \"TCP_dport\"], inplace=True)\n",
    "        df.to_csv(\"temp.csv\")\n",
    "        df=pd.read_csv(\"temp.csv\")\n",
    "        df[\"ID\"] = df[\"WS_src\"]+\"=>\"+df[\"WS_dst\"]\n",
    "        df.drop(columns=[\"WS_src\", \"WS_dst\"], inplace=True)\n",
    "\n",
    "        df[df.columns[-1]]=df[df.columns[-1]].astype(str)\n",
    "        IDS=sorted(list(df[df.columns[-1]].unique()))\n",
    "        func_sw=[mean,std] #functions\n",
    "        func_ew=[diff,\n",
    "                 std_EW,sum_of_EW] #functions\n",
    "        func_name_sw=[\"mean\",\"std\"]\n",
    "        func_name_ew=[\"diff\",\n",
    "                    #   \"mean_WE\",\n",
    "                      \"std_WE\",\n",
    "                      \"sum_of_EW\"]\n",
    "        f_list=[\n",
    "            \"pck_size\",\n",
    "            \"ts\",\n",
    "            'TCP_window',\n",
    "            ]\n",
    "        fark=[\n",
    "         'pck_size_mean',\n",
    "         'pck_size_std',\n",
    "         'ts_mean',\n",
    "         'ts_std',\n",
    "         'TCP_window_mean',\n",
    "         'TCP_window_std',\n",
    "         ]\n",
    "        WS=windows_size\n",
    "        flag=1\n",
    "        for i in tqdm(IDS):\n",
    "            # print('i',i)\n",
    "            smaller = df[df[\"ID\"]==i]\n",
    "            smaller=smaller.reset_index()\n",
    "            del smaller[\"index\"]\n",
    "            # ts = các ID trùng nhau trừ đi IP đầu,ID 1  - ID 0, ID 2 - ID 0\n",
    "            smaller[\"ts\"]=smaller[\"ts\"].values-smaller[\"ts\"].values[0]\n",
    "            for ii in f_list: # đặt tên và gán giá trị ví dụ ts_mean , ts_std\n",
    "                for jjj,iii in enumerate (func_ew):\n",
    "                    name=str(ii)+\"_\"+str(func_name_ew[jjj])\n",
    "                    smaller[name]=iii(smaller[ii])\n",
    "            # có ID trùng nhau  >= WS mới tính sw\n",
    "            if len(smaller)>=WS:\n",
    "                # tính toán giá trị dùng roll window\n",
    "                for ii in f_list:\n",
    "                    for jjj,iii in enumerate (func_sw):\n",
    "                        name=str(ii)+\"_\"+str(func_name_sw[jjj])\n",
    "                        smaller[name]=iii(smaller[ii],WS)\n",
    "            else:\n",
    "                for ii in fark:\n",
    "                        smaller[ii]=0\n",
    "            smaller['TCP_FIN_sum'  ]=flagsum (smaller[ 'TCP_FIN'  ].values)\n",
    "            smaller['TCP_SYN_sum'  ]=flagsum (smaller['TCP_SYN'  ].values)\n",
    "            smaller['TCP_RST_sum'  ]=flagsum (smaller['TCP_RST'  ].values)\n",
    "            smaller['TCP_PSH_sum'  ]=flagsum (smaller['TCP_PSH'  ].values)\n",
    "            smaller['TCP_ACK_sum'  ]=flagsum (smaller['TCP_ACK'  ].values)\n",
    "            smaller['TCP_URG_sum'  ]=flagsum (smaller['TCP_URG'  ].values)\n",
    "            smaller['TCP_ECE_sum'  ]=flagsum (smaller['TCP_ECE'  ].values)\n",
    "            smaller['TCP_CWR_sum'  ]=flagsum (smaller['TCP_CWR'  ].values)\n",
    "            smaller[\"TCP_SYN_ratio\"]=smaller[\"TCP_SYN\"]/(smaller[\"TCP_SYN_sum\"]+10e-20)\n",
    "            col_list= [\"TCP_FIN_sum\",\"TCP_SYN_sum\",\"TCP_RST_sum\",\"TCP_PSH_sum\",\"TCP_ACK_sum\",\"TCP_URG_sum\",\"TCP_ECE_sum\",\"TCP_CWR_sum\"]\n",
    "            smaller['sum'] = smaller[col_list].sum(axis=1)\n",
    "            smaller[\"TCP_ACK_SR\"]=smaller[\"TCP_ACK\"]/(smaller[\"sum\"]+10e-20)\n",
    "            smaller[\"TCP_ACK_R\"]=smaller[\"TCP_ACK_sum\"]/(smaller[\"sum\"]+10e-20)\n",
    "\n",
    "            if flag:\n",
    "                smaller.to_csv(j[5:],header=True,index=False)\n",
    "                flag=0\n",
    "            else:\n",
    "                smaller.to_csv(j[5:],header=False,index=False,mode=\"a\")\n",
    "        df=pd.read_csv(j[5:])\n",
    "        features=df.columns\n",
    "        count=[]\n",
    "        bos=[]\n",
    "        df=df.sort_values(by='Unnamed: 0')\n",
    "        last_name=f'./{outputfolder}/last_{str(WS)}_{j[5:]}'\n",
    "        df.to_csv(last_name,index=None)\n",
    "        print(WS,\"-------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOCktUkrPOv3"
   },
   "source": [
    "# MERGE SW FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfuTpNluPOv3",
    "outputId": "e705d52a-f33b-47d1-97a6-d1d0e867ce82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object walk at 0x000002C5BBA83570>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object walk at 0x000002C5BBA83570>\n",
      "2\n",
      "{'pck_size_mean': 'pck_size_mean_2', 'pck_size_std': 'pck_size_std_2', 'ts_mean': 'ts_mean_2', 'ts_std': 'ts_std_2', 'TCP_window_mean': 'TCP_window_mean_2', 'TCP_window_std': 'TCP_window_std_2'}\n",
      "6\n",
      "{'pck_size_mean': 'pck_size_mean_6', 'pck_size_std': 'pck_size_std_6', 'ts_mean': 'ts_mean_6', 'ts_std': 'ts_std_6', 'TCP_window_mean': 'TCP_window_mean_6', 'TCP_window_std': 'TCP_window_std_6'}\n",
      "9\n",
      "{'pck_size_mean': 'pck_size_mean_9', 'pck_size_std': 'pck_size_std_9', 'ts_mean': 'ts_mean_9', 'ts_std': 'ts_std_9', 'TCP_window_mean': 'TCP_window_mean_9', 'TCP_window_std': 'TCP_window_std_9'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.20it/s]\n"
     ]
    }
   ],
   "source": [
    "files_add=find_the_way('./SW','FE.csv')\n",
    "unique_file_names=[]\n",
    "for i in files_add:\n",
    "    bas=i.replace('_', '@', 1).find('_')+1\n",
    "    if i[bas:] not in unique_file_names:\n",
    "        unique_file_names.append(i[bas:])\n",
    "for i in tqdm(unique_file_names):\n",
    "    files_add=find_the_way('./SW',i)\n",
    "    flag=1\n",
    "    for ii in files_add:\n",
    "        WS=ii.split(\"_\")[1]\n",
    "        print(WS)\n",
    "        new_cols={'pck_size_mean':f'pck_size_mean_{WS}',\n",
    "        'pck_size_std':f'pck_size_std_{WS}',\n",
    "        'ts_mean':f'ts_mean_{WS}',\n",
    "        'ts_std':f'ts_std_{WS}',\n",
    "        'TCP_window_mean':f'TCP_window_mean_{WS}',\n",
    "        'TCP_window_std':f'TCP_window_std_{WS}',\n",
    "        # 'payload_bytes_mean':f'payload_bytes_mean_{WS}',\n",
    "        # 'payload_bytes_std':f'payload_bytes_std_{WS}',\n",
    "        # 'entropy_mean':f'entropy_mean_{WS}',\n",
    "        # 'entropy_std':f'entropy_std_{WS}'\n",
    "        }\n",
    "\n",
    "        print(new_cols)\n",
    "        if flag:\n",
    "             df=pd.read_csv(ii)\n",
    "             df.rename(columns = new_cols, inplace = True)\n",
    "             flag=0\n",
    "        else:\n",
    "            adding=pd.read_csv(ii,usecols=list(new_cols.keys()))\n",
    "            adding.rename(columns = new_cols, inplace = True)\n",
    "            df = pd.concat([df, adding], axis=1)\n",
    "        os.remove(ii)\n",
    "    temp=i.replace(\"_FE.\",\"_SW.\")\n",
    "    temp=f\"./SW/{temp}\"\n",
    "    # y=df[\"Label\"]\n",
    "    # del df[\"Label\"]\n",
    "    # df[\"Label\"]=y\n",
    "    df.to_csv(temp,index=False)\n",
    "    #print(list(df.columns))\n",
    "    #print(f\"{WS}\\n\\n\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "(105) feature exracto_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
